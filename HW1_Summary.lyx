#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement H
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder false
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle true
\pdf_pagemode FullScreen
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 3cm
\topmargin 3cm
\rightmargin 3cm
\bottommargin 3cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Computer Vision - HW1
\end_layout

\begin_layout Author
Lior Motola, Ofek Glick
\end_layout

\begin_layout Abstract
In this assignment, our goal is performing object detection on tools.
 The proposed algorithm for identifying surgical tools in a video involves
 three main stages: object detection, usage prediction, and visualization.
 The object detection stage uses a computer vision algorithm to identify
 the presence of surgical tools and hands in an image, and returns the bounding
 box dimensions and predicted class of the detected objects.
 The usage prediction stage uses a sliding mechanism to predict which tool
 is being used in each hand based on the history of tool usage.
 The visualization stage overlays the bounding boxes and tool usage predictions
 on top of the original video frames.
 This algorithm has the potential to improve the efficiency and accuracy
 of surgical processes.
 
\end_layout

\begin_layout Abstract
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section
Exploratory Data Analysis
\end_layout

\begin_layout Standard
\align left
We are working on a dataset of images, extracted from videos of medical
 personal performing surgical techniques in a training setting environment.Our
 dataset consists of a total of 1125 images of doctors working with the
 medical tools: 
\begin_inset Quotes eld
\end_inset

Scissors
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

Needle Driver
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

Forceps
\begin_inset Quotes erd
\end_inset

.
 Each image in the dataset is labeled with bounding boxes that encapsulate
 the medical tool and the hand that is using it and each bounding box is
 annotated accordingly.
 
\end_layout

\begin_layout Standard
\align center
\begin_inset Graphics
	filename example_image.jpeg
	lyxscale 25
	scale 25

\end_inset

 
\begin_inset Graphics
	filename example_image_2.jpeg
	lyxscale 25
	scale 25

\end_inset


\end_layout

\begin_layout Standard
First we explored some basic statistics regarding our data:
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename rep_before.jpeg
	lyxscale 15
	scale 15

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Label Distribution
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename image_label_dist_before.jpeg
	lyxscale 15
	scale 15

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Label count per image
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align left
Intial insights - 
\end_layout

\begin_layout Enumerate
\align left
Out of 1125 images, 3 images mistakenly had no annotations.
\end_layout

\begin_layout Enumerate
The 
\begin_inset Quotes eld
\end_inset

Right Forceps
\begin_inset Quotes erd
\end_inset

 label had no appearance in the dataset.
\end_layout

\begin_layout Enumerate
Some images had mislabeled bounding boxes.
 
\end_layout

\begin_layout Enumerate
Some labels are significantly less represented than others.
\end_layout

\begin_layout Enumerate
Most images have two labels, and a few have one label.
 Surprisingly, a single image had three labels.
\end_layout

\begin_layout Standard
\align left
To make sure our data is sound, we examined some of the images with a single
 label and three labels:
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename example of three.jpeg
	lyxscale 25
	scale 25

\end_inset

 
\begin_inset Graphics
	filename example of one.jpeg
	lyxscale 25
	scale 25

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
As expected, the image with a single label has one hand out of the frame.
 The image with three labels mistakenly had an extra bounding box.
 This was corrected.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
After correcting technical issues such as issue 3&5 we reperformed our analyses
 to get a better feel of our dataset.
 
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename label representation.jpeg
	lyxscale 25
	scale 25

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Label distribution, as can be seen, the labels 
\begin_inset Quotes eld
\end_inset

Right Forceps
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

Left Scissors
\begin_inset Quotes erd
\end_inset

 are absent, this is caused by the fact that most physicians were right
 handed.
 
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename image_label_dist_after.jpeg
	lyxscale 25
	scale 25

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Label count per image - Now there are no 
\begin_inset Quotes eld
\end_inset

extra
\begin_inset Quotes erd
\end_inset

 labels and all images have either 1 or 2 labels
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\align left
To tackle the issue of the label imbalance, we will attempt to syntheically
 create more image samples by flipping the images and switching the labels
 accordingly in order to 
\begin_inset Quotes eld
\end_inset

inject
\begin_inset Quotes erd
\end_inset

 more samples of left handed physicians in to the dataset.
\end_layout

\begin_layout Section
Experiments
\end_layout

\begin_layout Standard
In the section we describe multiple aspects that are configurable in our
 experiements.
 We will list them in the following section and describe the performed experimen
ts later on.
\end_layout

\begin_layout Subsection
Data loading, pre-processing and cleaning
\end_layout

\begin_layout Standard
At section 1, we discussed issues with our data.
 In the preprocessing stage we corrected mislabeled images, deleted excess
 labels and deleted unannotated images.
 Additionally, we experimented with flipping the images and their labels
 in order to artificially introduce images of left handed physicians to
 handle the imbalance of our labels.
\end_layout

\begin_layout Standard
\align center
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename flip1.jpeg
	lyxscale 25
	scale 25

\end_inset

 
\begin_inset Graphics
	filename flip2.jpeg
	lyxscale 25
	scale 25

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Example of an image flipped with the labels flipped accordingly
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Architecture
\end_layout

\begin_layout Standard
Throughout the experiments we used the YOLOv5 architecture.
 The YOLOv5 architecture consists of a backbone, neck and head components.
 The models backbone is used mainly to extract important features from the
 given input image, YOLOv5 uses the 
\begin_inset CommandInset href
LatexCommand href
name "CSP - Cross Stage Partial Network"
target "https://arxiv.org/abs/1911.11929"
literal "false"

\end_inset

 as it's backbone because it displayed significant improvement in processing
 time.
 The model neck is mainly used to generate 
\begin_inset Quotes eld
\end_inset

feature pyramids
\begin_inset Quotes erd
\end_inset

 which are helpful in generalizing on objects in differet scales, meaning
 that it helps identify the same object in different sizes and scales.
 YOLOv5 uses 
\begin_inset CommandInset href
LatexCommand href
name "PANet"
target "https://arxiv.org/abs/1803.01534"
literal "false"

\end_inset

.
 The model head is mainly used to perform the final detection part.
 It applies anchor boxes on features and generates final output vectors
 with class probabilities, objectness scores, and boundingÂ boxes.
 YOLOv5 uses the same head as YOLOv3 and YOLOv4.
\end_layout

\begin_layout Standard
In the YOLOv5 Framework they developed the same model in different sizes:
 Nano, Small, Medium, Large and XLarge.
 The models differ in parameters amount and inference speed.
\end_layout

\begin_layout Subsection
Loss functions
\end_layout

\begin_layout Standard
The YOLOv5 loss function consists of 3 parts: Classes loss (BCE loss), Objectnes
s loss (BCE loss) and Location loss (CIoU loss).
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
Loss=\lambda_{1}L_{cls}+\lambda_{2}L_{obj}+\lambda_{3}L_{loc}
\]

\end_inset


\end_layout

\begin_layout Standard
In the loss function, the 
\begin_inset Formula $L_{cls}$
\end_inset

 component referes to the probability that the class predicted for a certain
 bounding box is the correct class.
 The 
\begin_inset Formula $L_{loc}$
\end_inset

 component referes to the predicted bounding IoU with the golden labels
 bounding box which basically means how close to the true bounding box was
 our predicted bounding box.
 The 
\begin_inset Formula $L_{obj}$
\end_inset

 loss referes to the probability that the predicted bounding box indeed
 contains an object within it's borders.
\end_layout

\begin_layout Standard
The objectness probability is calculated at three different layers in our
 network and the losses of the three prediction layers are weighted differently
 like so:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
L_{obj}=4\cdot L_{obj}^{small}+L_{obj}^{medium}+0.4\cdot L_{obj}^{large}
\]

\end_inset


\end_layout

\begin_layout Subsection
Optimizers
\end_layout

\begin_layout Standard
In YOLOv5 we have the option to train with either SGD or ADAM optimizers.
\end_layout

\begin_layout Subsection
Regularization
\end_layout

\begin_layout Standard
YOLOv5 has many configurable regularization parameters, for example 
\begin_inset Formula $\lambda_{1},\lambda_{2},\lambda_{3}$
\end_inset

 described in section 2.3, we used the default regularization parameters
 given to us in the YOLOv5 implementation.
\end_layout

\begin_layout Subsection
Hyperparameter tuning
\end_layout

\begin_layout Standard
YOLOv5 enables us to perform hyperparameter tuning automatically using a
 built-in Genetic Algorithm which explores different hyperparameters using
 biology inspired metrics.
\end_layout

\begin_layout Standard
Our hyperparameters include optimizer parameters such as learning rate and
 momentum, loss regularization parameters, data augmentation probabilities
 such as hue change, image rotations and more.
 In all our experiments we did not allow the model to horizontally flip
 the images.
\end_layout

\begin_layout Section
Evaluation
\end_layout

\begin_layout Standard
In the section we will present the setting for our experiments as well as
 their results.
\end_layout

\begin_layout Subsection
Experiment 1
\end_layout

\begin_layout Standard
In experiment 1 we chose the following configuration: We used the enriched
 dataset after flipping all the images and their labels, the 
\series bold
small
\series default
 YOLOv5 architecture, the 
\series bold
SGD
\series default
 optimizer and we used the 
\series bold
optimal
\series default
 hyperparameters found after running the GA for five generations where each
 generation was trained on 40 epochs.
\end_layout

\begin_layout Standard
After find the optimal hyperparameters, we have trained our model accordingly
 and have received the following results
\end_layout

\begin_layout Subsection
Experiment 2
\end_layout

\begin_layout Standard
In experiment 2 we chose the following configuration: We used the enriched
 dataset after flipping all the images and their labels, the 
\series bold
medium
\series default
 YOLOv5 architecture, the 
\series bold
SGD
\series default
 optimizer and we used the 
\series bold
optimal
\series default
 hyperparameters found after running the GA for five generations where each
 generation was trained on 40 epochs.
\end_layout

\begin_layout Standard
After find the optimal hyperparameters, we have trained our model accordingly
 and have received the following results:
\end_layout

\begin_layout Section
Discussion and Conclusions
\end_layout

\end_body
\end_document
